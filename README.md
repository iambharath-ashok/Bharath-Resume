# Bharath-Resume
Bharath Ashok Full Stack Developer


                                                Bharath Ashok
                                          iambharath.ashoka@gmail.com
                                             +91 88618-66209
                                        https://github.com/iambharath-ashok


#### PROFESSIONAL SUMMARY:
-  Java Full Stack Developer with 4+ years of professional IT experience in Java/J2EE, MEAN Stack, Microservices, Cloud Computing, DevOps Implementation, Build & Release Engineering and Linux Administration.
-  Highly motivated, experienced Java Developer, effective at Multitasking and working under pressure to accomplish overall objectives.
-  “Go to Guy” when a solution is needed. Able to analyze business needs and formulate creative design and technical approaches in both individual and team settings.
-  Ability to dissect, understand, utilize and implement new complex APIs for common business use cases and to coach, mentor train less experienced team members.
-  Expansive knowledge and research capabilities to uncover latest technology developments to employ into solutions.
-  Ability to adapt to new and changing environments, learning new frameworks, design patterns, architecture and programming languages.
-  Capable of excelling as an individual developer or within a small to large team development environments. 
-  Effective communication skills to translate business and architectural requirements into actual implementation. 
-  Experience in all phases of Software Development Life Cycle (SDLC) methodologies like Agile/Scrum which includes Analysis, Design, Development, Implementation and Testing of enterprise business applications.
-  Experienced in developing the Enterprise Web Applications on n-tier architecture using Java/J2EE technologies such as Servlets, JSP, Hibernate, Spring, EJBs, JNDI, Web Services, SOA, XML, JPA, JMS and JDBC.
-  Expertise in Microservices communicating through HTTP protocol by implementing SOA specifications and worked with Microservices patterns - Circuit Breaker/Hystrix, DDD, Aggregator, Proxy Chaining.
-  Extensive knowledge on the Spring Modules like Spring Data, Spring IOC, Spring REST, Spring MVC, Spring Batch, Spring Web Flow, Spring Web-Reactive, Spring Security (Authentication and Authorization), Spring AOP for Code Modularity and Spring Boot, Spring Microservices.
-  Expertise in Spring Cloud Components like Spring Cloud Config Server, Netflix Feign, Netflix Ribbon, Netflix Eureka Naming Server, Netflix Zuul API Gateway, Netflix Zipkin Distributed Tracing, Fault Tolerance using Hystrix.
-  Developed and deployed Microservices based applications using Spring Boot along with Spring REST, Node JS with Express JS, Angular and Hapi.js
-  Good knowledge in OAuth 2.0 Protocol, Http Basic Auth and experienced in implementing custom validations, entity validations, I18N features.
-  Expertise to interact with relational databases using ORM frameworks like Hibernate, Spring Data, JPA, Java Persistence API (JPA), Hibernate’s second level cache - Ehcache.
-  Extensively developed SOAP services on webservice engines like Apache CXF, AXIS 2.x by implementing JAX-WS API and used WS Security standards like WS-Remote Messaging, WS -Security, WS- Policy. 
-  Expertise in XML Technologies XML, XSLT, XSD, Xml Schema and parsers like SAX and DOM. Experienced in developing applications that access XML files using JAXB, JAXP APIs.
-  Experience in using Mule soft which is light weight Java based Enterprise Service Bus (ESB) which allows connecting applications together quickly and easily, enabling them to exchange data.
-  Experience in using open source framework Apache Camel to design various EIP (Enterprise Integration Patterns) like Message Splitter, Aggregator, Message Route Builder etc.
-  Expertise in deploying applications on Application and Web Servers - IBM WebSphere, BEA WebLogic, JBoss, Apache Tomcat, Jetty and Glassfish.
-  Expertise in working with JAVA8 features like Functional Interfaces, Stream API, Time API, Transaction Management, Exception Handling, Collection API, Lambda Expressions.
-  Experience in Java Thread Dump Analysis and familiar with thread dump techniques.
-  Experience with various J2EE Design Patterns and GOF Design Patterns.
-  Strong working knowledge on Relational (RDBMS) and NOSQL databases like MS-SQL, Oracle 12c/ 11g/ 10g, MongoDB, Sybase, MySQL, H2Database, CouchDB, Cassandra, PostgreSQL, Redis, Teradata, Dynamo DB.
-  Developed complex SQL queries including stored procedures, triggers, user defined functions and views by using Oracle, MySQL and MS SQL Server.
-  Expertise in Cloud Infrastructure Automation which includes PCF, Kubernetes, Amazon Web Services (AWS), OpenStack, Ansible, Puppet, Maven, Jenkins, Chef, Go CD, GitHub, GitLab, WebLogic, Tomcat, JBOSS, and LINUX etc.
-  Experience in building applications hosted on Cloud and good understanding of Cloud Modules like Infrastructure as a Service (IaaS) Platform as a Service (PaaS), Software as a Service (SaaS).
-  Hands on experience on PaaS stacks like Google Cloud Platform (GCP), Amazon Web Services (AWS) and Pivotal Cloud Foundry (PCF).
-  Extensive experience in working with AWS resources like IAM, EC2, EBS, S3, ELB, VPC, ECS, Lambda, Route 53, Auto Scaling, Cloud Watch, Cloud Front, Cloud Trail, Red Shift, SQS, SNS.
-  Hands on experience in setting up database in AWS using RDS, storage using S3 bucket and configuring instance backups to S3 bucket to ensure fault tolerance and high availability.
-  Experienced with event-driven and scheduled AWS Lambda functions to trigger various AWS resources and Cloud computing infrastructure such as Amazon Dynamo DB, Amazon SQS, Redshift.
-  Expertise in developing and deploying Spring Boot-based Microservices on Pivotal Cloud Foundry (PCF).
-  Provided consistent environment using Kubernetes for deployment scaling and load balancing to the application from development through production, easing the code development and deployment by implementing Docker Containerization.
-  Good Knowledge on Docker Images, Docker Compose, Docker Swarm and experience in Containerizing the applications using Docker.
-  Experience with installation and configuration of Docker Environment including Docker Registry for managing different Docker Images and deployment of applications inside the Software Containers.
-  Expertise in Apache Kafka and Elastic Stack (ElasticSearch, Logstash, Kibana) and implemented a pipeline for Centralized Logging for Payment Applications across multiple environments by creating many Kibana Dashboards and Visualizations.
-  Expertise in Orchestrating ELK Containers with Kubernetes and Docker on the Cloud Services like AWS and Elastic Cloud.
-  Extensively worked on Jenkins and implementation experience of CI/CD Pipelines for End-to-End Automation for all build and deployments by creating Jenkins Jobs and Pipelines and solving various problems with ANT, Maven, Gradle as plugins.
-  Good knowledge about Splunk Architecture and various components (Indexer, Forwarder, Search Heads, Deployment Server), Heavy and Universal forwarder, License model.
-  Experience in developing Splunk Queries and Dashboards targeted at understanding application performance and capacity analysis. 
-  Expertise in creating SOAP/REST Virtual Services using CA Dev/Test Software.
-  Experience with Object-Oriented Client-side Scripting using Typescript, ES6 and JavaScript frameworks, including jQuery, Angular.
-  Expertise in developing and designing Single Page Application (SPA) user interfaces in Angular 2.x/4. X/5.0 and deploying them on Google Firebase.
-  Expertise in using shadow DOM which is a feature of Angular 5 to encapsulate visual behavior.
-  Good knowledge in providing support for passing messages between publishers and subscribers using observables as a part of Angular 5.
-  Experienced in building MEAN applications using MongoDB, Express JS, Angular, Node JS, creating Restful Web services to interact with UI Interfaces using REST API with Node JS, Express JS and installing client-side dependencies using BOWER and YEOMAN.
-  Extensively used Node Package Manager (NPM) to manage or install the Node JS modules like Grunt, Gulp, and Express.js, Mongoose, mongo.js, body-parser, bcrypt.js and socket.io …. etc.
-  Experience in implementing Mongo DB CRUD operations by using Mongoose library in Node-JS including Angular.
-  Experienced in React JS and working with React flux architecture, Redux architecture using complex Object-Oriented concepts in improving the performance of the websites.
-  Worked with React JS and its components typically rendered React views, which contain additional components specified as custom HTML tags.
-  Worked on writing quality code using TDD (Test driven development) and unit tested using JavaScript testing frameworks Jasmine, Karma, Mocha, Chai, and Protractor to write the tests on both client side and server side.
-  Sound knowledge in working with cross-browser/platform compatibility issues with browsers like IE, Firefox, Safari, Opera, Chrome using Modernizr. 
-  Expertise in making builds & deploying application to Cloud Platform like Heroku server.
-  Good working experience on bug tracking tools like JIRA, CRM, Bugzilla, Remedy and qTrack in Testing phase.
-  Strong understanding on working with SCM/Version Control System (VCS) tools like SVN, Serena Dimensions, Git Hub and GitLab.
-  Extensive experience in working on design, development, testing, implementation, deployment, enhancements & production support in Linux/Unix and Windows environments/Platforms.

#### TECHNICAL SKILLS:


Programming Languages:  Java, Groovy
Scripting Languages:  JavaScript, UNIX Shell Scripting, Perl Scripting
Mark up Languages: HTML5, CSS3, XML, XSLT, YML
Operating systems: Mac, Linux, Unix, Windows 10/8/7/Vista/XP, RedHat Linux, CentOS, Ubuntu, Solaris
J2EE Technologies: Servlets, JSP, JSTL, JMS, JDBC, EJB, JNDI, JPA, JTA, XML, JAXB, DOM, SAX
Frameworks: Log4J, Log4J2, Slf4J, Logback, Spring 3.x/4.x/5.x, Hibernate 3.x, 4.x, 5.x, JPA, JDBC, JMS, Apache Tiles, Jasper API, Freemarker, Thymeleaf
Messaging Systems: Apache ActiveMQ, Rabbit MQ, HornetQ, Apache Kafka
Web Services: JAX-WS, JAX-RS, SOAP, WSDL, UDDI, REST, Apache CXF, Apache Axis 2.x Jersey, RestEasy, Swagger2
Web Technologies: HTML5, CSS3, LESS, SASS, SCSS, JavaScript, JQuery, AJAX, Bootstrap, JSON, XML
Libraries and Frameworks:  Angular 2.x/4.x/5.x, React JS, Node JS, Backbone JS, Bootstrap, Express JS, mongoose, mongo.js, body-parser, bcrypt.js, socket.io.
SQL/NoSQL Databases: MongoDB, Dynamo DB, CouchDB, PostgreSQL, MySQL, MS-SQ, Oracle 12C/11g/10g/9i, MySQL, SQL Server, PL/SQL, DB2.
Development IDEs: Eclipse, Microsoft Visual Studio, IntelliJ, Notepad++, Sublime Text, Atom IO, Bracket, TOAD and SQL Developer, SQLyog, MySQL Workbench
Web/Application Servers: IBM Web Sphere, BEA WebLogic, Apache Tomcat, JBOSS, Glassfish, Jetty, Embedded Tomcat
Build Tools: Ant, Maven, Gradle
Version Control Tools: SVN, Serena Dimensions, GitHub, GitLab, Nexus
Bug Tracking Tools: CA Rally, JIRA, Bugzilla, Remedy, HP Quality Center, SonarQube, FindBugs, Fortify Code Analyzer
Unit Testing Framework: JUnit, TestNG, Mockito, Power Mock, Protractor, Jasmine along with Karma, Mocha, Selenium, Spring JUnit 4, Cucumber
Testing Tools: WinRunner and LoadRunner, SOAPUI, Postman, Rest Client UI
Debugging Tools: Firebug, Chrome Developer Tools, IE Developer Toolbar.
CI/CD Tools: Jenkins, Buildforge, Go CD, GitLab CI, Travis CI, Circle CI
DevOps Tools: Git, SonarQube, Apache Kafka, Splunk, Elastic Search, Kibana, Graylog, Logstash, Jfrog Artifactory
Configuration Management Tools: Chef, Puppet, Ansible
Splunk: Splunk 5.x and 6.x, Splunk Enterprise, Splunk on Splunk, Splunk DB 2 Connect, Splunk Cloud, Hunk, Splunk IT Service Intelligence, Splunk Web Framework
Cloud Platforms:  Amazon Web Services(AWS), Google Cloud Platform (GCP) and Pivotal Cloud Foundry, OpenStack, Heroku
Container Platforms: Docker, Kubernetes, OpenShift, Mesos
Virtualization Tools: Oracle VM Virtual Box, Vagrant, VMware Workstation and Windows Hyper-V
Monitoring Tools: Nagios, Splunk, Log Stash, Cloud watch, Elasticsearch
Network Protocols: TCP/IP, DHCP, DNS, SNMP, SMTP, Ethernet, NFS
Methodology: Agile Methodology
Agile Tools: CA Rally
Service Virtualization Tools:  CA Dev/Test
Other Tools: PuTTY, Microsoft Visio, Fire Bug, WinSCP, FileZilla, MobaXterm, Firebase

#### WORK HISTORY:
-  Currently working as a Senior Software Developer at CenturyLink India Pvt Ltd from September 2015 to till date
-  Worked as Software Developer at Web Affinity Technologies Pvt Ltd from November 2014 to August 2015

#### PROFESSIONAL EXPERIENCE:
##### ATTOM – AT &T Order Management
	
	ATTOM is a Spring Boot based Microservice deployed at AWS with Angular 5 as UI Client. ATTOM will used to order and browse the AT & T Products for CenturyLink Customers in a Highly Secured Manner using B2B VPN. ATTOM will interface with many CenturyLink Source applications and AT & T Services to display AT & T Products on CenturyLink Portals. CenturyLink Agents and Customers can use ATTOM UI to place Order for AT & T Services and Products through CenturyLink.
	
Java Full Stack Developer
CenturyLink India Pvt Ltd, Bangalore, KA

###### Responsibilities:
-  Developed Single Page Responsive Web UI using Angular 5, Express JS, HTML5, CSS3(using SAAS), Bootstrap, TypeScript.
-  Implemented Angular 5 component router for navigation, Angular 5 services to connect the web application to back-end APIs. Followed ES6 coding standard and coding best practices.
-  Programmed in Angular 5 to upload(post) files/images to the AWS S3 browser from the Front-end by installing NPM package of AWS-SDK.
-  Developed multiple POCs to create an interface between Backend to Frontend by using MongoDB, Express JS, Angular 5 and Node JS.
-  Extensively used promises (Success and Error) while making sync communication. Wrote services with Angular 5 to store and retrieve user data from the Mongo DB for the application on devices with the Http service.
-  Created Angular 5 components, implemented Interpolation, Input variables, Bootstrapping, NgFor, NgIf, Router-Outlet, binding the click event, Component decorator, binding to the hidden property.
-  Configured Typescript application through tsconfig file for various purposes like trans piling, debugging, tracing, generating separate folder for distributable etc.
-  Client-Side code was written in Angular 5 and Server-Side code was developed using Spring MVC 5.
-  Used SASS based CSS to define the styles in the application and used Webpack module bundler to bundle the code.
-  Developed RESTful service interface using Spring Boot to the underlying Agent Services API and implemented RESTful web services.
-  Build prototype for various required services such as Scheduling, Logging and Notification Service using third party Node JS based JavaScript library.
-  Worked with the Node package manager (NPM) along with Grunt and used JASMINE and KARMA for UNIT testing.
-  Used WireMock to create Mock APIs for local testing.
-  Used OAuth 2 which is a lightweight authentication framework with a central authorization server and generates an access token to access a protected resource on a resource server.
-  Documented Spring RESTful APIs with Swagger2 to help customers better understand APIs.
-  Designed, configured and deployed Amazon Web Services (AWS) for a multitude of applications utilizing the Amazon Web Services focusing on high-availability, fault tolerance and auto-scaling.
-  Installed the application on AWS EC2 instances and configured the storage on S3 buckets.
-  Designed and implemented scalable, secure cloud architecture based on Amazon Web Services (AWS).
-  Worked on creation of custom Docker container images, tagging and pushing the images to CenturyLink corporate Docker Hub.
-  Developed Microservices using Spring Cloud Netflix OSS stack to address Load balancing using Ribbon, API Gateway using Zuul.
-  Kubernetes is configured in the application for automating deployment, scaling, and management of containerized applications.
-  Used Apache Kafka (Message Queues) for reliable and asynchronous exchange of vital information between multiple business applications.
-  Utilized AWS Lambda platform to upload data into AWS S3 buckets and to trigger other Lambda functions.
-  Plan, deploy, monitor, and maintain Amazon AWS cloud infrastructure consisting of multiple EC2 nodes and VM's as required in the environment using AWS Cloud Watch.
-  Created collections and performed CRUD operations on MongoDB using Node Mongoose and used mongo repository and Spring MongoTemplate for persistence.

Tools and Environment: AWS, Red Hat Linux, Java 8/J2EE, Spring, Hibernate, Spring Boot, Microservices, Angular 5, Node JS,HTML, Embedded Tomcat, MongoDB, Grunt, Spring Data Rest, Eclipse, Junit, Bootstrap, Go CD, GitLab, Typescript, Docker, Kubernetes, Swagger, Kafka, Spring Cloud Modules, NPM, SASS, Bootstrap, Jira, Spring Junit4, WireMock, Jasmine, Webpack

##### CIPS – CenturyLink Integrated Payment Services

	CIPS is a Microservice originally hosted on top of Node Server and Pivotal Cloud Foundry (PCF) and later migrated to Kubernetes Cluster of CenturyLink Omaha Data Center as part of Company’s cost reduction initiative. CIPS is a non-PCI compliant App, it's been designed and implemented to migrate non-PCI Monolithic architecture from PCI Tier 2 EPWF App to Microservice architecture. CIPS will interface with multiple Payment Apps to provide services like Payments History, Refund, Manage, Adjust Payments to Downstream and Upstream Apps. React JS has been used to implement Front-end and to render views to Client.
	
Java Full Stack Developer
CenturyLink India Pvt Ltd, Bangalore, KA

###### Responsibilities:
-  The back-end use of Node JS, Express JS, React JS MongoDB and Mongoose, the complete MERN Stack to provide RESTful API.
-  Implemented client-side Interface using React JS.
-  Built user interfaces differently by breaking them into components using React JS and used a real, full featured programming language to render views, with React JS.
-  Responsible for implementing UI mockups, integrating third party react libraries, and handling/creating Redux store data.
-  Developed React/Redux code using functional programming best practices to enable efficient pure function testing.
-  Utilized Modernizer extensively to build HTML5/CSS3 based page layouts that are cross-browser compatible and standards-compliant.
-  Worked on responsive design and developed a single ISOMORPHIC responsive website that could be served to desktop, Tablets and mobile users using React JS.
-  Implemented application testability and diagnostics and fixing bugs with the help of REDUX(Reducers) architecture.
-  Utilized create-react-app to launch product to stay update with the most current webpack and babel build configurations.
-  Handled Http Requests using Axios which supports Promise API functionality native to JS ES6.
-  Worked with Babel and Webpack in application build and deployment processes.
-  Used Pivotal Cloud Foundry (PCF) to quickly build, deploy and update the applications.
-  Extensively used GO CD and GitLab CI as Continuous Deployment tools to deploy the Apps to Pivotal Cloud Foundry (PCF) using build pack.
-  Responsible for automating builds with Go CD, GitLab CI and publishing Docker Images to the CenturyLink Corporate Docker Hub.
-  Orchestrating Container deployment and management using Kubernetes on CenturyLink Omaha Data Center.
-  Used JWT (JSON web tokens) mechanism for authentication and authorization security configurations using Node JS.
-  Have successfully migrated Apps running on Pivotal Cloud Foundry (PCF) to Kubernetes Cluster and used Kubernetes web-based UI to manage applications running in the cluster and troubleshoot them, as well as manage the cluster itself. 
-  Unstructured data was handled using MongoDB and used Mongoose Connector for connecting to database.
-  Involved in implementing queries to the backend MongoDB database using Http service to fetch JSON contract.
-  Performed unit testing with Mocha and Chai JavaScript test framework.
-  Ran Log aggregations, website Activity tracking and commit log for distributed system using Apache Kafka.
-  Have used Splunk to monitor the application, forwarding application logs, debugging logs and created Splunk Alerts for operational team about critical errors and exceptions.

Tools and Environment: Kubernetes Cluster, Kuberentes, Omaha Data Center, Docker, Pivotal Cloud Foundry, React JS, MongoDB, Splunk, Mocha, Chai, JWT, Go CD, GitLab CI, AXIOS, Babel and Webpack, REST API, Node, Express JS, Redux


##### EPWFBATCH – Electronic Payment Work Flow Batch

	EPWFBATCH is a rewrite application of legacy EPWFBAT application. EPWFBATCH is designed and implemented around Apache Camel Framework to integrate wide variety of Enterprise Systems. EPWFBATCH will handle batch payment processing application loading 10-30 million dollars in payments a day. EPWFBATCH will manage very huge load of Payment Records, processes records and Post them to respective Billing Applications. 
	
Sr. Java/J2ee Developer
CenturyLink India Pvt Ltd, Bangalore, KA

###### Responsibilities:
-  Integrated web services using Apache Camel routing and implemented Camel DSL scripts to route messages.
-  Used Apache Camel to design various EIP (Enterprise Integration Patterns) like Message Splitter, Aggregator, Message Route Builder etc.,
-  Successfully Integrated Apache CXF-RS with Apache Camel to provide RESTful services to downstream applications.
-  Developed Spring JMS integration layer using Camel-JMS Component and efficient business components to process MQ messages.
-  Developed database, web service, messaging adapters and custom workflow for multiple systems using Camel.
-  Extensively worked on Camel components like Bean IO, Bean Validator, Dozer, CXF, CXFRS, Dozer, FreeMarker, HTTP, JMS, JPA, Kafka, Mock, Quartz2, SQL, JDBC.
-  Used Camel Bean IO component to marshal and unmarshall file contents to Java objects and vice versa.
-  Used Camel Dozer component customize Object conversion from one type to another type
-  Used Gradle as a build tool for the application and written complete Gradle scripts to build EAR, TAR and upload TAR to Serena Source Control System.
-  Integrated Quart2 Framework with Apache Camel and Spring Framework for implementing Quartz Jobs for to Process wide variety of Payment Files.
-  Implemented temporary UI to manage Quartz2 Jobs using Vaadin Framework.
-  Developed Angular SPA as the UI for application and implemented variety of functionalities to manage the Quartz2 Jobs, Processed Files and Charts etc.
-  Successfully implemented RESTful services and used Angular HTTP module to consume the back-end service to populate data on the SPA.
-  Implemented Angular4 component router for navigation, Angular 4 services to connect the web application to back-end APIs. Followed ES6 coding standard and coding best practices.
-  Used Jasper API to generate Payments Daily reports and many client reports.
-  Created HTML5 Email templates using Thymeleaf a modern server-side Java template engine and integrated with Camel for each processed file
-  Implemented CXF Soap Client to consume services from external applications.
-  Done extensive Research and Development to create many POCs for the application.
-  Created Jenkins pipeline and automated End-to-End flow from building application to Continuous Integration and Continuous Deployment.
-  Lead Reviews done to evaluate the code to ensure that it is valid, is properly structured, and meets industry standards.
-  Developed test cases by using PowerMock, Mockito and Easy Mock for unit testing for each module developed in Test Driven Development (TDD).
-  Installation, configuration and deployment of J2EE components on JBOSS EAP using Eclipse IDE and from Jenkins.

Tools and Environment: Apache Camel, Thymeleaf, Jasper API, Java 8, Eclipse Mars, JBOSS, Vaadin, Angular 4, Quatz2, LINUX GNU, Gradle, Groovy, Jenkins


##### Splunk Developer
CenturyLink India Pvt Ltd, Bangalore, KA

###### Responsibilities:
-  Worked as a Splunk Admin for Creating and Managing app, Creating users, role, Permissions to Payment Applications.
-  Working with Splunk Authentication and Permissions and having significant experience in supporting large scale Splunk Deployments. 
-  Installing Splunk Apps for Windows, Linux environments and good knowledge on Configuration files in Splunk (props.conf, Transforms.conf, Output.conf) Time chart attributes such as span, bins, Tag, event types, creating dashboards, reports using XML.
-  Configuring Splunk on docker container to forward application logs on Splunk.
-  Writing Splunk Queries, expertise in searching, monitoring, analyzing and visualizing Splunk logs.
-  Involved in Splunk Report generation and providing statistics report to Management on weekly basis.
-  Writing logs in the right format to be picked by Splunk tool, use Splunk to debug log messages.
-  Worked on large datasets to generate insights by using Splunk and played a major role in understanding the logs, server data and brought an insight of the data for the users.
-  Created Dashboards for various types of business needs and handle SWAT situations for the Payment Apps.
-  Assisted internal users of Splunk in designing and maintaining production-quality dashboard.
-  Created alerts based on the critical parameters, which will trigger emails to the operational and development team.
-  Optimized the search performance of Splunk queries and reduced the time for loading the dashboards.
-  Optimized Splunk for peak performance by splitting Splunk indexing and search activities across different machines.
-  Created Search Commands to retrieve multiline log events in the form Single transaction giving Start Line and End Line as inputs.
-  Responsible for troubleshooting various indexing issues by analyzing Splunk logs such as splunkd.log, metrics.log ingested as internal index.

Tools and Environment: Linux, Windows, Splunk 5.x and 6.x, Splunk Enterprise, Splunk on Splunk, Splunk DB 2 Connect, Splunk Cloud, Hunk, Splunk IT Service Intelligence, Splunk Web Framework


##### Elastic Stack Developer
CenturyLink India Pvt Ltd, Bangalore, KA

###### Responsibilities:
-  Worked on configuring ELK {Elasticsearch, Logstash, Kibana} Stack and Zookeeper, Kafka cluster for data ingestion and on Kafka for live streaming of data.
-  Design, build and manage the ELK (ElasticSearch, Logstash, Kibana) stack for centralized logging and search functionalities for CenturyLink Payment Applications.
-  Built centralized logging to enable better debugging using Elasticsearch Logstash, Kibana and Kafka.
-  Configured Kafka-Manager and used Kafka-Manager Web UI to monitor and manage multiple clusters of Kafka, topics on Kafka nodes.
-  Used ELK stack for logging and monitoring our systems end to end Using Beats.
-  Writing input, filters and ouput for Logstash.
-  Written all the Grok filters in Logstash to trim and customize the data before pushing them to Elasticsearch.
-  Configuring Logstash across multiple platforms and writing configuration file with multiple plugins to read data from multiple data-sources like kafka, filebeat, tcp, JMS etc.
-  Setting up, configuring filebeat on edge servers to push the logs to ES or Logstash servers and Indexing using filebeat with Logstash.
-  Learned to index and search/query millions of documents inside Elasticsearch.
-  Generating a histogram or even a date histogram (a histogram over time) using Elasticsearch giving it an interval to bucket the data into two weeks.
-  Using X-pack for monitoring, Security on Elasticsearch-5.6.4 cluster.
-  Using Kibana interface to filter and visualize log messages gathered by an Elastic Stack.
-  Configured Kibana data visualization plugin for Elasticsearch, Logstash and created bar, line and scatter plots, or pie charts and maps on top of large volumes of data.
-  SPOC for all ELK and Kafka related requests/issues for CenturyLink Payment Applications.
-  Developed a POC for cloud-based integrations with Elastic Cloud and Amazon Web Service (AWS).
-  Snapshot Elasticsearch Indices data and archive in the repository every 12 hours.
-  Created indexes, mappings and data in Elasticsearch and used Elasticsearch REST API's both single and multi-document API's like Index, Multi Get, Bulk ... etc. 
-  Responsible to designing and orchestrating new ELK Docker container clusters (Elasticsearch, Logstash, Kibana, beats, Kafka, Zookeeper) using Kubernetes on Elastic Cloud.

Tools and Environment: ELK 4.x, 5.x, 6.x, Red Hat Linux, Elasticsearch, Kibana, Logstash, Apache Kafka, X-pack, Filebeat, Beats, GrayLog, Elastic Cloud, Amazon AWS, Linux GNU, Zookeeper, Kafka Manager, Docker, Kubernetes, Shell Scripts, Unix commands

	
##### Confidential - Jenkins Automated Continuous Delivery (CD) Plugin

	Continuous Delivery (CD) Jenkins Plugin Tool is designed to automate Test Install to decrease Build lifecycle gap between Dev and Test Team. Since CenturyLink System Test Environment will be maintained by Enterprise Testing System (ETS) team, each team should to raise a ticket for each Test Install. Continuous Deliver Plugin have automated System Test Install by making a HTTPS REST Call to DopSis service of ETS and Test Install will be completed as part of Jenkins build Lifecycle of App.
	
Sr. Java/J2ee Developer
CenturyLink India Pvt Ltd, Bangalore, KA

###### Responsibilities:
-  Understanding of Jenkins Object Model and used its core interface, APIs of Hudson model like Recorder, AbstractBuild, Extension, Launcher, AbstractBuild, BuildListener, Publisher, ListBoxModel, FormValidation as part plugin implementation.
-  Have used Jelly as the view technology to create and render the views of plugin. Used Jelly Tag Libraries to define the form controls.
-  Have used Stapler Library to bind the Java Instances to URL.
-  Created many POCs before implementation of plugin.
-  Created REST Client using Apache HTTPClient Library to consume RESTful service from multiple external systems.
-  Have used Jackson Object Mapper to serialize outgoing JSON requests from POJOs and deserialize incoming JSON requests to POJOs.
-  Code written in Java 8 and have extensively used Lambda Expressions, Functional Interfaces, Stream API, Time API.
-  Used J2EE Design Patterns like Factory, Observer, DTO, DAO, MVC Session Facade, Business Delegate, Service Locater, Transfer Object and GOF Design Patterns. 
-  Have used JDBC and used Builder, Façade, Decorator, Bridge, Template, Command design patterns to connect to 5 different Oracle Database servers and 2 different MS SQL Database Servers.
-  Have successfully used the Continuous Delivery Plugin across the organization from CenturyLink’s Corporate Jenkins to various internal teams for their own Jenkins instances.
-  Providing support, sending notifications about functionality changes for multiple teams across the organization and SPOC for all the plugin related queries.

Tools and Environment: Jenkins, Red Hat Linux Box, Java 8, Design Patterns, Jenkins Object Model, Jenkins Plugins, JDBC, Apache HTTP Client, JAX-RS, REST, HTTPS, SSL, Stapler, Jelly, MS SQL, Oracle SQL, Jackson fasterxml Library.


#####  EPWF – Electronic Payment Work Flow

	EPWF is an in house built centralized Payment management and processing application within CenturyLink. It interfaces with many different applications like IVR, Retail Stores, RPS (Check processing system), My Account (Consumer Self Service portal), JANUS (Small/Medium/Large Business Self Service portal), QPORTAL (Enterprise Business Self Service Portal) and many more to process all types of CenturyLink Payments. It provides wide variety of services (Single/Multiple, One Time/Schedule/Recurring, Update/Cancel etc.) to support different needs of the applications. It interacts with multiple external Payment Vendors like IBM, Speedpay (Western Union), JPMC, and PayPal to process different types of Payments. It manages Payment life cycle from Payment initiation till Posting to Billing Systems.
	
Sr. Java/J2ee Developer
CenturyLink India Pvt Ltd, Bangalore, KA

###### Responsibilities:
-  Participated in project planning sessions with business analysts and team members to analyze business requirements and translated business requirements into working model.
-  Agile implementation by daily SCRUMS and day-to-day user interactions.
-  Involved in requirement analysis, creating Low-Level and High-Level Design, development, review and system integration phases.
-  Handle bugs in production environment from multiple systems with sharp response times.
-  Coordinate with multiple teams, internal as well as 3rd party software providers, for resolving the bugs.
-  Used MDW (Model Driven Workflow) BPM tool to manage business flow for the application.
-  Providing maintenance support on weekend to applications with more than Ten millions of users, fixing bugs and improving the applications.
-  Designed & developed SOAP and RESTful web services using WSDL, SOAP, JAX-WS, JAX-RS, JAXB and Apache CXF.
-  Implemented code for marshal and unmarshall technique using JAXB to parse XML to string object and vice versa.
-  Extensively used DOM and SAX parsers for parsing XML data and XSLT for XML transformations.
-  Used XSL/XSLT for transforming common XML format into internal XML format.
-  Writing Ant build scripts and deploying application to various environments using Jenkins.
-  Have developed Centralized Logging Framework using Log4j and Slf4j binding to append the logs to Kafka Broker.
-  Used Jackson Object Mapper and JSON API to transform XML requests and responses to JSON to send logs to Splunk.
-  Extensively used Hibernate concepts such as inheritance, lazy loading, dirty checking, locking, and transactions.
-  Have used EJB 3 Session and Entity beans to manage system level services like transaction handling, persistence mechanism, exception handling.
-  Responsibility included leading/mentoring team members, code reviews, overall solution/technical design and direction to the stake holders, development, QA and Operation teams.

Tools and Environment: BEA Web Logic 10.3, Linux GNU, JSON, Jackson, JSON API, Ant, Jenkins, Hibernet, EJB 3, Splunk, Log4j, Slf4J, Remedy, CA Rally, DOM, SAX, XML, JAX-RS, JAX-WS, Apache CXF, WSDL, JAXB, XSL, Java 1.6, Eclipse Indigo, MDW


#####  HCDE – Hosted Card Data Environment

	HCDE is a web application used for securing Customer’s Credit Card details for all the payments done to CenturyLink in any channel. To comply with Payment Card Industry (PCI) standards, CenturyLink has come up with this thought provoking idea to standardize and centrally integrate all the payment channels under a single roof. This application provides a web service which manages storing and validating customer’s, Credit card details while making payments to CenturyLink. Any application accepting CenturyLink card payments must be integrated with HCDE and HCDE provides a web service where in customer’s credit card details are validated and a token is returned from HCDE for each successful credit card authentication. In this way, HCDE is providing a secured environment for the Credit card payments done to CenturyLink and all other applications can simply make use of this hassle-free service from HCDE.
	
Sr Java/J2ee Developer
CenturyLink India Pvt Ltd, Bangalore, KA

###### Responsibilities:
-  Used Spring DI, annotations and MVC to implement business layer and navigation part of application.
-  Developed SOAP and RESTful clients to communicate with multiple External Payment Gateway systems.
-  Worked with an Architect team to set up the initial project architecture in Spring Batch framework.
-  Developed Spring Batch application for batch processing using Spring4.x and improved the performance of the backend batch processes using Java Concurrent API.
-  Designed and Implemented Spring Batch jobs on Daily/Weekly/Monthly based by using triggers and schedulers. 
-  Setup Spring 4.x Job by configuring job Tasklets, Quartz Scheduler and Listeners for error handling.
-  Implemented pre-authentication and data base security using Spring security.
-  Involved in integrating Spring with Hibernate and delegated the persistence operations using HibernateTemplate.
-  Developed DAOs Data Access Objects and performed O/R mapping using Hibernate to access data-base.
-  Implemented Hibernate Second level of caching using Ehcache provider to get caching across session factory.
-  Used Spring JTA Transaction manager to remove the dependencies on the container.
-  Used JSP's in the presentation layer along with JSTL tags, CSS and JavaScript.
-  Implemented logging using log4j and various cross-project functionalities using Spring AOP.
-  Support integrated release with checklists for the CMS/JS/CSS artifacts that need to be deployed to production server.
-  Developed Maven scripts and CI/CD pipelines using Jenkins.
-  Handling build, deployment and Prod release activities.
-  Replaced the existing logging framework with Slf4j Log4J2 binding to simplify the logging process.

Tools and Environment: JSP, CSS, Spring 4.x, Spring Batch, Spring AOP, Spring Security, Jenkins, Maven, Hibernate, Ehcache, Quartz API, JavaScript, Java 7, Spring Tool Suite (STS), Java Reflection API, Slf4j, Log4J


#####  Online Table Reservation Portal – Evening Flavors
Online Dining and Partying Portal is a Web Application can be used by Customers wishing to Book Restaurant Tables by browsing number of Restaurants by Buffets, Cuisines, different kind of events like Parties, DJ Night, Resorts with lot of Packages on a one click. Portal includes some of the user engagement activities like Share, Like, Wishlist, Bookmark, Been there. Apart from that customer can browse number of Deals with specific Restaurants and can Buy Tickets for events.
Java/J2ee Developer
Web Affinity Private Ltd, Bangalore, KA

###### Responsibilities:
-  Developed classes using Core Java concepts like Multithreading, Concurrency, and Memory Management.
-  Implemented various J2EE patterns like MVC, Singleton Pattern, Factory Pattern, Abstract Factory pattern, Data Access Objects, Adaptor(Wrapper) Pattern.
-  Introduced Deals Module in an Application. Integrated Reservation Dairy a third-Party REST API in application.
-  Developed User Engagement Module like bookmark, wish list, like, share, upload photos.
-  Successfully integrated Social Media login for portal customers using Facebook Login and Google Plus API.
-  Migrated application from JDBC and implemented Persistence layer using Hibernate ORM tool.
-  Implemented Responsive design for Presentation layer using Bootstrap3. Extensively worked on Business layer and DAO layer.
-  Responsible for the set-up and maintenance of the content management system, CSS, JavaScript, or other programming related to the site.
-  Written well designed, efficient, testable code and wrote application level code to perform client-side validation using JQuery and JavaScript.
-  Extensively used $http service to make AJAX calls and consume JSON response across numerous services.
-  Developed complex SQL queries to fetch data, MySQL as a database management system.
-  Used log4j for logging and debugging purposes. UNIX commands to check the application logs.

Tools and Environment: Ajax, JQuery, JSP, Servlets, JSON, REST, Hibernate, JDBC, MySQL, SQLyog, MySQL Workbench, Log4J, Bootstarp, Design Pattrens

#### AWARDS & NOMINATIONS:
-  Awarded Spot award 3 times, consecutively twice for Jenkins Continuous Delivery Plugin and Centralized Logging Framework implementation
-  Awarded CenturyLink Star Award in 2017
-  Promoted from Software Developer to Senior Software Developer in 2017
-  Nominated for Outstanding Performer in 2016 
-  Awarded CenturyLink Outstanding Team of BSS Division in 2016

#### EDUCATIONAL QUALIFICATIONS:
-  Completed Master of Technology on Computer Science from Rashtreeya Vidyalaya College of Engineering (RVCE) in 2014
-  Completed Bachelor of Engineering on Information Science from Jawaharlal Nehru National College of Engineering (JNNCE) in 2012

